<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>smartsolve.models &mdash; smartsolve 0.0.1 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            smartsolve
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../modules.html">smartsolve</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">smartsolve</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">smartsolve.models</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for smartsolve.models</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">multivariate_normal</span>



<div class="viewcode-block" id="LinearRegression"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.LinearRegression">[docs]</a><span class="k">class</span> <span class="nc">LinearRegression</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span>  <span class="n">coefficients</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span>
                 <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="s1">&#39;yes&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize a Linear Regression model.</span>
<span class="sd">        parameters:</span>
<span class="sd">        :param train_data: Training data in the form of [(y1,[x11,x12,...,x1n]),(y2,[x21,x22,x2n])</span>
<span class="sd">                          ,...,(ym,[xm1,xm2,...,xmn])].</span>
<span class="sd">        :param coefficients: Initial coefficients for the model (default is None).</span>
<span class="sd">        :param bias: Bias term for the model (default is None).</span>
<span class="sd">        :param learning_rate: Learning rate for gradient descent (default is 1e-2).</span>
<span class="sd">        :param max_iter: Maximum number of iterations for gradient descent (default is 1000).</span>
<span class="sd">        :param threshold: Convergence threshold for gradient descent (default is 1e-8).</span>
<span class="sd">        :param seed: Random seed for reproducibility (default is 42).</span>
<span class="sd">        :param norm: Normalize features or not (&#39;yes&#39; or &#39;no&#39;, default is &#39;yes&#39;).</span>
<span class="sd">        output:</span>
<span class="sd">        None</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coefficients</span> <span class="o">=</span> <span class="n">coefficients</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">means</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stds</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mse</span> <span class="o">=</span> <span class="p">[]</span>

<div class="viewcode-block" id="LinearRegression.mean_squared_error"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.LinearRegression.mean_squared_error">[docs]</a>    <span class="k">def</span> <span class="nf">mean_squared_error</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">predicted</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate the Mean Squared Error (MSE) between actual labels and predicted labels.</span>

<span class="sd">        :param labels: Actual labels.</span>
<span class="sd">        :param predicted: Predicted labels.</span>
<span class="sd">        :return: Mean Squared Error.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">labels</span> <span class="o">-</span> <span class="n">predicted</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">mse</span></div>

<div class="viewcode-block" id="LinearRegression.stoch_gradient"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.LinearRegression.stoch_gradient">[docs]</a>    <span class="k">def</span> <span class="nf">stoch_gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">coefficients</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform a stochastic gradient descent step.</span>

<span class="sd">        :param features: Feature matrix.</span>
<span class="sd">        :param labels: Actual labels.</span>
<span class="sd">        :param coefficients: Current model coefficients.</span>
<span class="sd">        :param index: Index of the data point for the stochastic gradient descent step.</span>
<span class="sd">        :return: Updated coefficients after the step.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">difference</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="p">:],</span> <span class="n">coefficients</span><span class="p">)</span> <span class="o">-</span> <span class="n">labels</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="n">gradient</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">difference</span>

        <span class="n">num_points</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

        <span class="n">new_weights</span> <span class="o">=</span> <span class="n">coefficients</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">/</span> <span class="n">num_points</span><span class="p">)</span> <span class="o">*</span> <span class="n">gradient</span>

        <span class="k">return</span> <span class="n">new_weights</span></div>

<div class="viewcode-block" id="LinearRegression.stoch_gradient_descent"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.LinearRegression.stoch_gradient_descent">[docs]</a>    <span class="k">def</span> <span class="nf">stoch_gradient_descent</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">coefficients</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform stochastic gradient descent to optimize model coefficients.</span>

<span class="sd">        :param features: Feature matrix.</span>
<span class="sd">        :param labels: Actual labels.</span>
<span class="sd">        :param coefficients: Initial model coefficients.</span>
<span class="sd">        :return: Optimized coefficients.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">co_dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="n">coefficients</span> <span class="o">=</span> <span class="n">coefficients</span>

        <span class="n">num_iter</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

        <span class="k">while</span> <span class="n">co_dist</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="ow">and</span> <span class="n">num_iter</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">:</span>

            <span class="n">random_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

            <span class="n">new_coefficients</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stoch_gradient</span><span class="p">(</span>
                <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
                <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
                <span class="n">coefficients</span><span class="o">=</span><span class="n">coefficients</span><span class="p">,</span>
                <span class="n">index</span><span class="o">=</span><span class="n">random_index</span>
            <span class="p">)</span>

            <span class="n">mse</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">coefficients</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mse</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>

            <span class="n">num_iter</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="n">co_dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">coefficients</span> <span class="o">-</span> <span class="n">co_dist</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

            <span class="n">coefficients</span> <span class="o">=</span> <span class="n">new_coefficients</span>

        <span class="k">return</span> <span class="n">coefficients</span></div>

<div class="viewcode-block" id="LinearRegression.train"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.LinearRegression.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train the Linear Regression model on the provided training data.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">point</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">])</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">point</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">])</span>

        <span class="c1"># Store the means and stds to normalize the features when needed for predictions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">==</span> <span class="s1">&#39;yes&#39;</span><span class="p">:</span>
            <span class="n">features</span> <span class="o">=</span> <span class="p">(</span><span class="n">features</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">means</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">stds</span>

        <span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">),</span> <span class="n">features</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">coefficients</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coefficients</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">coefficients</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stoch_gradient_descent</span><span class="p">(</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
            <span class="n">coefficients</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">coefficients</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="LinearRegression.predict"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.LinearRegression.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="s1">&#39;no&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predict labels for input data.</span>

<span class="sd">        :param data: Input data for which to make predictions.</span>
<span class="sd">        :param norm: Normalize data or not (&#39;yes&#39; or &#39;no&#39;, default is &#39;no&#39;).</span>
<span class="sd">        :return: Predicted labels.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">norm</span> <span class="o">==</span> <span class="s1">&#39;yes&#39;</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">means</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">stds</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">),</span> <span class="n">data</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">predicted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">coefficients</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">predicted</span></div></div>




<div class="viewcode-block" id="LogisticRegression"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.LogisticRegression">[docs]</a><span class="k">class</span> <span class="nc">LogisticRegression</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">coefficients</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span>
                 <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="s1">&#39;yes&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize a LogisticRegression model.</span>

<span class="sd">        :param train_data: Training data in the form [(y1,[x11,x12,...,x1n]), ... ,(ym,[xm1,xm2,...,xmn])].</span>
<span class="sd">        :param coefficients: Initial coefficients for the model (default is None).</span>
<span class="sd">        :param bias: Bias term (default is None).</span>
<span class="sd">        :param learning_rate: Learning rate for gradient descent (default is 1e-2).</span>
<span class="sd">        :param max_iter: Maximum number of iterations for gradient descent (default is 1000).</span>
<span class="sd">        :param threshold: Convergence threshold for stopping criteria (default is 1e-8).</span>
<span class="sd">        :param seed: Random seed for reproducibility (default is 42).</span>
<span class="sd">        :param norm: Whether to normalize features (&#39;yes&#39; or &#39;no&#39;, default is &#39;yes&#39;).</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coefficients</span> <span class="o">=</span> <span class="n">coefficients</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">means</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stds</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mse</span> <span class="o">=</span> <span class="p">[]</span>

<div class="viewcode-block" id="LogisticRegression.mean_squared_error"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.LogisticRegression.mean_squared_error">[docs]</a>    <span class="k">def</span> <span class="nf">mean_squared_error</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">predicted</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate the mean squared error between actual labels and predicted labels.</span>

<span class="sd">        :param labels: Actual labels.</span>
<span class="sd">        :param predicted: Predicted labels.</span>
<span class="sd">        :return: Mean squared error.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">labels</span> <span class="o">-</span> <span class="n">predicted</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">mse</span></div>

<div class="viewcode-block" id="LogisticRegression.sigmoid"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.LogisticRegression.sigmoid">[docs]</a>    <span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predicted</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the sigmoid function for the given predicted values.</span>

<span class="sd">        :param predicted: Predicted values.</span>
<span class="sd">        :return: Sigmoid-transformed values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">predicted</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">predicted</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">predicted</span></div>

<div class="viewcode-block" id="LogisticRegression.stoch_gradient"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.LogisticRegression.stoch_gradient">[docs]</a>    <span class="k">def</span> <span class="nf">stoch_gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">coefficients</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform a stochastic gradient descent step.</span>

<span class="sd">        :param features: Feature matrix.</span>
<span class="sd">        :param labels: Actual labels.</span>
<span class="sd">        :param coefficients: Current model coefficients.</span>
<span class="sd">        :param index: Index of the data point for the stochastic gradient descent step.</span>
<span class="sd">        :return: Updated coefficients after the step.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">predicted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="p">:],</span> <span class="n">coefficients</span><span class="p">)</span>

        <span class="n">predicted</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">predicted</span><span class="o">=</span><span class="n">predicted</span><span class="p">)</span>

        <span class="n">difference</span> <span class="o">=</span> <span class="n">predicted</span> <span class="o">-</span> <span class="n">labels</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

        <span class="n">gradient</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">difference</span>

        <span class="n">num_points</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

        <span class="n">new_coefficients</span> <span class="o">=</span> <span class="n">coefficients</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">/</span> <span class="n">num_points</span><span class="p">)</span> <span class="o">*</span> <span class="n">gradient</span>

        <span class="k">return</span> <span class="n">new_coefficients</span></div>

<div class="viewcode-block" id="LogisticRegression.stoch_gradient_descent"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.LogisticRegression.stoch_gradient_descent">[docs]</a>    <span class="k">def</span> <span class="nf">stoch_gradient_descent</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">coefficients</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform stochastic gradient descent.</span>

<span class="sd">        :param features: Feature matrix.</span>
<span class="sd">        :param labels: Actual labels.</span>
<span class="sd">        :param coefficients: Initial model coefficients.</span>
<span class="sd">        :return: Updated coefficients after gradient descent.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">co_dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="n">coefficients</span> <span class="o">=</span> <span class="n">coefficients</span>

        <span class="n">num_iter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

        <span class="k">while</span> <span class="n">co_dist</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="ow">and</span> <span class="n">num_iter</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">:</span>

            <span class="n">random_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

            <span class="n">new_coefficients</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stoch_gradient</span><span class="p">(</span>
                <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
                <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
                <span class="n">coefficients</span><span class="o">=</span><span class="n">coefficients</span><span class="p">,</span>
                <span class="n">index</span><span class="o">=</span><span class="n">random_index</span>
            <span class="p">)</span>

            <span class="n">mse</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">coefficients</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mse</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>

            <span class="n">num_iter</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="n">co_dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">coefficients</span> <span class="o">-</span> <span class="n">co_dist</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

            <span class="n">coefficients</span> <span class="o">=</span> <span class="n">new_coefficients</span>

        <span class="k">return</span> <span class="n">coefficients</span></div>

<div class="viewcode-block" id="LogisticRegression.train"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.LogisticRegression.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train the logistic regression model.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">point</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">])</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">point</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">])</span>

        <span class="c1"># Store the means and stds to normalize the features when needed for predictions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">==</span> <span class="s1">&#39;yes&#39;</span><span class="p">:</span>
            <span class="n">features</span> <span class="o">=</span> <span class="p">(</span><span class="n">features</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">means</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">stds</span>

        <span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">),</span> <span class="n">features</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">coefficients</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coefficients</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">coefficients</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stoch_gradient_descent</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
                                                        <span class="n">coefficients</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">coefficients</span><span class="p">)</span></div>

<div class="viewcode-block" id="LogisticRegression.predict"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.LogisticRegression.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="s1">&#39;no&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predict labels for the given data.</span>

<span class="sd">        :param data: Data for which to make predictions.</span>
<span class="sd">        :param norm: Whether to normalize features (&#39;yes&#39; or &#39;no&#39;, default is &#39;no&#39;).</span>
<span class="sd">        :return: Predicted labels.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">norm</span> <span class="o">==</span> <span class="s1">&#39;yes&#39;</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">means</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">stds</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">),</span> <span class="n">data</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">predicted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">coefficients</span><span class="p">)</span>

        <span class="n">predicted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="n">predicted</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">predicted</span></div>


<div class="viewcode-block" id="LogisticRegression.ppredict"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.LogisticRegression.ppredict">[docs]</a>    <span class="k">def</span> <span class="nf">ppredict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform probability predictions for the given data.</span>

<span class="sd">        :param data: Data for which to make probability predictions.</span>
<span class="sd">        :return: Probability predictions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">==</span> <span class="s1">&#39;yes&#39;</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">means</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">stds</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">),</span> <span class="n">data</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">predicted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">coefficients</span><span class="p">)</span>

        <span class="n">predicted</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">predicted</span></div></div>




<div class="viewcode-block" id="DecisionTree"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.DecisionTree">[docs]</a><span class="k">class</span> <span class="nc">DecisionTree</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A Decision Tree classifier for binary classification problems.</span>

<span class="sd">    :param train_data: The training data.</span>
<span class="sd">    :param min_points: The minimum number of data points required to split a node (default is 2).</span>
<span class="sd">    :param max_depth: The maximum depth of the decision tree (default is 10).</span>
<span class="sd">    :param num_features: The number of random features to consider for each split (default is None).</span>
<span class="sd">    :param curr_depth: The current depth of the tree while building (default is 0).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">min_points</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">curr_depth</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_points</span> <span class="o">=</span> <span class="n">min_points</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span> <span class="o">=</span> <span class="n">max_depth</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span> <span class="o">=</span> <span class="n">num_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">curr_depth</span> <span class="o">=</span> <span class="n">curr_depth</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="DecisionTree.train"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.DecisionTree.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train the decision tree on the provided training data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">point</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">])</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">point</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">])</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tree</span><span class="p">(</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
            <span class="n">curr_depth</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">curr_depth</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="DecisionTree.tree"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.DecisionTree.tree">[docs]</a>    <span class="k">def</span> <span class="nf">tree</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">curr_depth</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Recursively build the decision tree.</span>

<span class="sd">        :param features: The features of the data.</span>
<span class="sd">        :param labels: The labels of the data.</span>
<span class="sd">        :param curr_depth: The current depth in the tree.</span>
<span class="sd">        :return: The root node of the decision tree.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">num_points</span><span class="p">,</span> <span class="n">num_features</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">num_labels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">curr_depth</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span> <span class="ow">or</span> <span class="n">num_labels</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">num_points</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_points</span><span class="p">:</span>
            <span class="n">leaf_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_label</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">DecisionTreeNode</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">leaf_value</span><span class="p">)</span>

        <span class="n">feature_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">num_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">best_feature</span><span class="p">,</span> <span class="n">best_threshold</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_split</span><span class="p">(</span>
            <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
            <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
            <span class="n">feature_index</span><span class="o">=</span><span class="n">feature_index</span>
        <span class="p">)</span>

        <span class="n">left_index</span><span class="p">,</span> <span class="n">right_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
            <span class="n">column</span><span class="o">=</span><span class="n">features</span><span class="p">[:,</span> <span class="n">best_feature</span><span class="p">],</span>
            <span class="n">threshold</span><span class="o">=</span><span class="n">best_threshold</span>
        <span class="p">)</span>

        <span class="n">left</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tree</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="n">left_index</span><span class="p">,</span> <span class="p">:],</span> <span class="n">labels</span><span class="p">[</span><span class="n">left_index</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">curr_depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">right</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tree</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="n">right_index</span><span class="p">,</span> <span class="p">:],</span> <span class="n">labels</span><span class="p">[</span><span class="n">right_index</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">curr_depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">DecisionTreeNode</span><span class="p">(</span><span class="n">best_feature</span><span class="p">,</span> <span class="n">best_threshold</span><span class="p">,</span> <span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">)</span></div>

<div class="viewcode-block" id="DecisionTree.best_split"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.DecisionTree.best_split">[docs]</a>    <span class="k">def</span> <span class="nf">best_split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">feature_index</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Find the best feature and threshold for splitting the data.</span>

<span class="sd">        :param features: The features of the data.</span>
<span class="sd">        :param labels: The labels of the data.</span>
<span class="sd">        :param feature_index: The indices of features to consider for splitting.</span>
<span class="sd">        :return: The best feature and threshold for splitting.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">best_gain</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="n">split_index</span><span class="p">,</span> <span class="n">split_threshold</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>

        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">feature_index</span><span class="p">:</span>
            <span class="n">column</span> <span class="o">=</span> <span class="n">features</span><span class="p">[:,</span> <span class="n">index</span><span class="p">]</span>
            <span class="n">thresholds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">column</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="n">thresholds</span><span class="p">:</span>

                <span class="n">gain</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">info_gain</span><span class="p">(</span>
                    <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
                    <span class="n">column</span><span class="o">=</span><span class="n">column</span><span class="p">,</span>
                    <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span>
                <span class="p">)</span>

                <span class="k">if</span> <span class="n">gain</span> <span class="o">&gt;</span> <span class="n">best_gain</span><span class="p">:</span>
                    <span class="n">best_gain</span> <span class="o">=</span> <span class="n">gain</span>
                    <span class="n">split_index</span> <span class="o">=</span> <span class="n">index</span>
                    <span class="n">split_threshold</span> <span class="o">=</span> <span class="n">threshold</span>

        <span class="k">return</span> <span class="n">split_index</span><span class="p">,</span> <span class="n">split_threshold</span></div>

<div class="viewcode-block" id="DecisionTree.info_gain"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.DecisionTree.info_gain">[docs]</a>    <span class="k">def</span> <span class="nf">info_gain</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">column</span><span class="p">,</span> <span class="n">threshold</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate the information gain for a split.</span>

<span class="sd">        :param labels: The labels of the data.</span>
<span class="sd">        :param column: The column (feature) being split.</span>
<span class="sd">        :param threshold: The threshold for splitting the column.</span>
<span class="sd">        :return: The information gain for the split.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">parent_entropy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">entropy</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

        <span class="n">left_index</span><span class="p">,</span> <span class="n">right_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">column</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">left_index</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">right_index</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>

        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">n_left</span><span class="p">,</span> <span class="n">n_right</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">left_index</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">right_index</span><span class="p">)</span>
        <span class="n">e_left</span><span class="p">,</span> <span class="n">e_right</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">entropy</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">[</span><span class="n">left_index</span><span class="p">]),</span> <span class="bp">self</span><span class="o">.</span><span class="n">entropy</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">[</span><span class="n">right_index</span><span class="p">])</span>
        <span class="n">child_entropy</span> <span class="o">=</span> <span class="p">(</span><span class="n">n_left</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="n">e_left</span> <span class="o">+</span> <span class="p">(</span><span class="n">n_right</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="n">e_right</span>

        <span class="n">info_gain</span> <span class="o">=</span> <span class="n">parent_entropy</span> <span class="o">-</span> <span class="n">child_entropy</span>

        <span class="k">return</span> <span class="n">info_gain</span></div>

<div class="viewcode-block" id="DecisionTree.split"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.DecisionTree.split">[docs]</a>    <span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">column</span><span class="p">,</span> <span class="n">threshold</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Split a column into left and right indices based on a threshold.</span>

<span class="sd">        :param column: The column (feature) to be split.</span>
<span class="sd">        :param threshold: The threshold for splitting the column.</span>
<span class="sd">        :return: Indices of the left and right subsets after the split.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">left_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">column</span> <span class="o">&lt;=</span> <span class="n">threshold</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="n">right_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">column</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">left_index</span><span class="p">,</span> <span class="n">right_index</span></div>

<div class="viewcode-block" id="DecisionTree.entropy"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.DecisionTree.entropy">[docs]</a>    <span class="k">def</span> <span class="nf">entropy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate the entropy of a set of labels.</span>

<span class="sd">        :param labels: The labels for which to calculate entropy.</span>
<span class="sd">        :return: The entropy of the labels.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">hist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">ps</span> <span class="o">=</span> <span class="n">hist</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

        <span class="n">entropy</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">p</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">ps</span> <span class="k">if</span> <span class="n">p</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">entropy</span></div>

<div class="viewcode-block" id="DecisionTree.best_label"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.DecisionTree.best_label">[docs]</a>    <span class="k">def</span> <span class="nf">best_label</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Find the most common label in a set of labels.</span>

<span class="sd">        :param labels: The labels for which to find the most common label.</span>
<span class="sd">        :return: The most common label.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">counter</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">counter</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">value</span></div>

<div class="viewcode-block" id="DecisionTree.predict"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.DecisionTree.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predict the labels for a set of data points.</span>

<span class="sd">        :param data: The data points for which to make predictions.</span>
<span class="sd">        :return: An array of predicted labels.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">traverse_tree</span><span class="p">(</span><span class="n">point</span><span class="o">=</span><span class="n">point</span><span class="p">,</span> <span class="n">node</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">)</span> <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="n">data</span><span class="p">])</span></div>

<div class="viewcode-block" id="DecisionTree.traverse_tree"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.DecisionTree.traverse_tree">[docs]</a>    <span class="k">def</span> <span class="nf">traverse_tree</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">point</span><span class="p">,</span> <span class="n">node</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Traverse the decision tree to predict a label for a data point.</span>

<span class="sd">        :param point: The data point for which to make a prediction.</span>
<span class="sd">        :param node: The current node in the decision tree.</span>
<span class="sd">        :return: The predicted label.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">leaf_node</span><span class="p">():</span>
            <span class="k">return</span> <span class="n">node</span><span class="o">.</span><span class="n">value</span>

        <span class="k">if</span> <span class="n">point</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">feature</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">node</span><span class="o">.</span><span class="n">threshold</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">traverse_tree</span><span class="p">(</span><span class="n">point</span><span class="p">,</span> <span class="n">node</span><span class="o">.</span><span class="n">left</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">traverse_tree</span><span class="p">(</span><span class="n">point</span><span class="p">,</span> <span class="n">node</span><span class="o">.</span><span class="n">right</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="DecisionTreeNode"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.DecisionTreeNode">[docs]</a><span class="k">class</span> <span class="nc">DecisionTreeNode</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize a node for a decision tree.</span>

<span class="sd">        :param feature: The feature index for the node.</span>
<span class="sd">        :param threshold: The threshold for splitting the feature.</span>
<span class="sd">        :param left: The left child node.</span>
<span class="sd">        :param right: The right child node.</span>
<span class="sd">        :param value: The predicted value for a leaf node.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature</span> <span class="o">=</span> <span class="n">feature</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">left</span> <span class="o">=</span> <span class="n">left</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">right</span> <span class="o">=</span> <span class="n">right</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">value</span>

<div class="viewcode-block" id="DecisionTreeNode.leaf_node"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.DecisionTreeNode.leaf_node">[docs]</a>    <span class="k">def</span> <span class="nf">leaf_node</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Check if the current node is a leaf node.</span>

<span class="sd">        :return: True if the node is a leaf, False otherwise.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span></div></div>




<div class="viewcode-block" id="RandomForest"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.RandomForest">[docs]</a><span class="k">class</span> <span class="nc">RandomForest</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">num_trees</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">min_points</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">curr_depth</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes a Random Forest classifier/regressor.</span>

<span class="sd">        :param train_data: Input training data in the form of [(y1, [x11, x12, ..., x1n]), (y2, [x21, x22, x2n]), ...].</span>
<span class="sd">        :param num_trees: The number of decision trees in the random forest (default is 30).</span>
<span class="sd">        :param max_depth: The maximum depth of each decision tree (default is 20).</span>
<span class="sd">        :param min_points: The minimum number of data points in a leaf node (default is 2).</span>
<span class="sd">        :param num_features: The number of features to consider at each split (default is None).</span>
<span class="sd">        :param curr_depth: The current depth of the random forest (default is 0).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_trees</span> <span class="o">=</span> <span class="n">num_trees</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span> <span class="o">=</span> <span class="n">max_depth</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_points</span> <span class="o">=</span> <span class="n">min_points</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span> <span class="o">=</span> <span class="n">num_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">curr_depth</span> <span class="o">=</span> <span class="n">curr_depth</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">trees</span> <span class="o">=</span> <span class="p">[]</span>

<div class="viewcode-block" id="RandomForest.fit"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.RandomForest.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fits the Random Forest model by training multiple decision trees.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_trees</span><span class="p">):</span>

            <span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTree</span><span class="p">(</span>
                <span class="n">train_data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">,</span>
                <span class="n">min_points</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">min_points</span><span class="p">,</span>
                <span class="n">max_depth</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span><span class="p">,</span>
                <span class="n">num_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_features</span><span class="p">,</span>
                <span class="n">curr_depth</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">curr_depth</span>
            <span class="p">)</span>

            <span class="n">tree</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trees</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tree</span><span class="p">)</span></div>

<div class="viewcode-block" id="RandomForest.best_label"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.RandomForest.best_label">[docs]</a>    <span class="k">def</span> <span class="nf">best_label</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prediction</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Finds the most common label in a list of predictions.</span>

<span class="sd">        :param prediction: List of predicted labels.</span>
<span class="sd">        :return: The most common label in the predictions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">counter</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>
        <span class="n">most_common</span> <span class="o">=</span> <span class="n">counter</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">most_common</span></div>

<div class="viewcode-block" id="RandomForest.predict"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.RandomForest.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predicts labels or values for the given features using the Random Forest.</span>

<span class="sd">        :param features: The features to make predictions for.</span>
<span class="sd">        :return: Predicted labels or values for the features.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">features</span><span class="p">)</span> <span class="k">for</span> <span class="n">tree</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">trees</span><span class="p">])</span>
        <span class="n">tree_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">best_label</span><span class="p">(</span><span class="n">prediction</span><span class="o">=</span><span class="n">prediction</span><span class="p">)</span> <span class="k">for</span> <span class="n">prediction</span> <span class="ow">in</span> <span class="n">tree_predictions</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">predictions</span></div></div>




<div class="viewcode-block" id="KMeansClustering"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.KMeansClustering">[docs]</a><span class="k">class</span> <span class="nc">KMeansClustering</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">num_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes a KMeansClustering object.</span>

<span class="sd">        :param train_data: The training data.</span>
<span class="sd">        :param num_clusters: The number of clusters to create.</span>
<span class="sd">        :param max_iter: The maximum number of iterations for the K-Means algorithm.</span>
<span class="sd">        :param threshold: The convergence threshold for centroid updates.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_clusters</span> <span class="o">=</span> <span class="n">num_clusters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_dims</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">clusters</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># a dictionary to store the detected clusters</span>

<div class="viewcode-block" id="KMeansClustering.train"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.KMeansClustering.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train the KMeans model on the provided data.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">)</span>
        <span class="n">prev_centroids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">initialization</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_clusters</span><span class="p">)</span>
        <span class="n">cluster</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">))]</span>
        <span class="n">cluster_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_clusters</span><span class="p">)]</span>
        <span class="n">change_centroids</span> <span class="o">=</span> <span class="mf">1e+10</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">):</span>

            <span class="k">if</span> <span class="n">change_centroids</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">:</span>

                <span class="n">cluster</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_clusters</span><span class="p">,</span> <span class="n">prev_centroids</span><span class="p">)</span>

                <span class="n">new_centroids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">centroids</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_clusters</span><span class="p">,</span> <span class="n">cluster</span><span class="p">)</span>
                <span class="n">change_centroids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">measure_change</span><span class="p">(</span><span class="n">new_centroids</span><span class="p">,</span> <span class="n">prev_centroids</span><span class="p">)</span>
                <span class="n">prev_centroids</span> <span class="o">=</span> <span class="n">new_centroids</span>

        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">cluster_keys</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">)):</span>
                <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="n">cluster</span><span class="p">[</span><span class="n">j</span><span class="p">]:</span>
                    <span class="k">if</span> <span class="sa">f</span><span class="s2">&quot;Cluster </span><span class="si">{</span><span class="n">key</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">clusters</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">clusters</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;Cluster </span><span class="si">{</span><span class="n">key</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">[</span><span class="n">j</span><span class="p">]]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">clusters</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;Cluster </span><span class="si">{</span><span class="n">key</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">[</span><span class="n">j</span><span class="p">])</span></div>

<div class="viewcode-block" id="KMeansClustering.initialization"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.KMeansClustering.initialization">[docs]</a>    <span class="k">def</span> <span class="nf">initialization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">num_clusters</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize cluster centroids using random data points from the dataset.</span>

<span class="sd">        :param data: The dataset for initialization.</span>
<span class="sd">        :param num_clusters: The number of clusters to create.</span>
<span class="sd">        :return: A NumPy array of initial cluster centroids.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">centroids</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">num_features</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_clusters</span><span class="p">):</span>
            <span class="n">centroid</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_features</span><span class="p">):</span>
                <span class="n">cx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]),</span> <span class="nb">max</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]))</span>
                <span class="n">centroid</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cx</span><span class="p">)</span>

            <span class="n">centroids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">centroid</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">centroids</span><span class="p">)</span></div>

<div class="viewcode-block" id="KMeansClustering.cluster"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.KMeansClustering.cluster">[docs]</a>    <span class="k">def</span> <span class="nf">cluster</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">data</span><span class="p">,</span> <span class="n">num_cluster</span><span class="p">,</span> <span class="n">prev_centroids</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Assign data points to clusters based on the closest centroid.</span>

<span class="sd">        :param data: The dataset to cluster.</span>
<span class="sd">        :param num_cluster: The number of clusters.</span>
<span class="sd">        :param prev_centroids: The previous cluster centroids.</span>
<span class="sd">        :return: An array of cluster assignments.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">cluster</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)):</span>
            <span class="n">dist_arr</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_cluster</span><span class="p">):</span>
                <span class="n">dist_arr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">distance</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">prev_centroids</span><span class="p">[</span><span class="n">j</span><span class="p">]))</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">dist_arr</span><span class="p">)</span>
            <span class="n">cluster</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">idx</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">cluster</span><span class="p">)</span></div>

<div class="viewcode-block" id="KMeansClustering.distance"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.KMeansClustering.distance">[docs]</a>    <span class="k">def</span> <span class="nf">distance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the Euclidean distance between two data points.</span>

<span class="sd">        :param a: The first data point.</span>
<span class="sd">        :param b: The second data point.</span>
<span class="sd">        :return: The Euclidean distance between a and b.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">distance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">a</span> <span class="o">-</span> <span class="n">b</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">distance</span></div>

<div class="viewcode-block" id="KMeansClustering.centroids"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.KMeansClustering.centroids">[docs]</a>    <span class="k">def</span> <span class="nf">centroids</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">num_cluster</span><span class="p">,</span> <span class="n">cluster</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute new centroids for each cluster based on the assigned data points.</span>

<span class="sd">        :param data: The dataset.</span>
<span class="sd">        :param num_cluster: The number of clusters.</span>
<span class="sd">        :param cluster: The cluster assignments for each data point.</span>
<span class="sd">        :return: An array of updated cluster centroids.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">cg_arr</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_cluster</span><span class="p">):</span>
            <span class="n">arr</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)):</span>
                <span class="k">if</span> <span class="n">cluster</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">:</span>
                    <span class="n">arr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
            <span class="n">cg_arr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">cg_arr</span><span class="p">)</span></div>

<div class="viewcode-block" id="KMeansClustering.measure_change"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.KMeansClustering.measure_change">[docs]</a>    <span class="k">def</span> <span class="nf">measure_change</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prev_centroids</span><span class="p">,</span> <span class="n">new_centroids</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Measure the change in centroids between iterations to check for convergence.</span>

<span class="sd">        :param prev_centroids: The centroids from the previous iteration.</span>
<span class="sd">        :param new_centroids: The updated centroids in the current iteration.</span>
<span class="sd">        :return: The measure of change in centroids.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">res</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">prev_centroids</span><span class="p">,</span> <span class="n">new_centroids</span><span class="p">):</span>
            <span class="n">res</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">distance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span></div></div>



<div class="viewcode-block" id="KNearestNeighbors"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.KNearestNeighbors">[docs]</a><span class="k">class</span> <span class="nc">KNearestNeighbors</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    K-Nearest Neighbors (KNN) algorithm for classification and regression.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        train_data (list): The training data in the format [(y1,[x11,x12,...,x1n]), ...].</span>
<span class="sd">        num_neighbors (int): The number of neighbors to consider (default is 5).</span>
<span class="sd">        distance (str): The distance metric to use (&#39;EU&#39;, &#39;MA, &#39;MI&#39;, &#39;CH&#39;, or &#39;CO&#39;).</span>
<span class="sd">        algorithm (str): The type of task (&#39;classification&#39; or &#39;regression&#39;).</span>
<span class="sd">        p_value (int): The p-value for the Minkowski distance (default is 2).</span>

<span class="sd">    Attributes:</span>
<span class="sd">        features (numpy.ndarray): The features of the training data.</span>
<span class="sd">        labels (numpy.ndarray): The labels of the training data.</span>

<span class="sd">    Methods:</span>
<span class="sd">        fit(): Fit the model to the training data.</span>
<span class="sd">        custom_distance(point1, point2): Calculate the custom distance between two data points.</span>
<span class="sd">        euclidean (point1, point2): Calculate the Euclidean distance between two points.</span>
<span class="sd">        manhattan(point1, point2): Calculate the Manhattan distance between two points.</span>
<span class="sd">        minkowski(point1, point2): Calculate the Minkowski distance between two points.</span>
<span class="sd">        chebyshev(point1, point2): Calculate the Chebyshev distance between two points.</span>
<span class="sd">        cosine(point1, point2): Calculate the Cosine distance between two points.</span>
<span class="sd">        predict(data): Make predictions for a list of data points.</span>
<span class="sd">        point_predict(point): Predict the class or value of a single data point.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">num_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">distance</span><span class="o">=</span><span class="s1">&#39;EU&#39;</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;classification&#39;</span><span class="p">,</span> <span class="n">p_value</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_neighbors</span> <span class="o">=</span> <span class="n">num_neighbors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">distance</span> <span class="o">=</span> <span class="n">distance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">algorithm</span> <span class="o">=</span> <span class="n">algorithm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p_value</span> <span class="o">=</span> <span class="n">p_value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="KNearestNeighbors.fit"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.KNearestNeighbors.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the model to the training data.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">point</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">point</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">])</span></div>

<div class="viewcode-block" id="KNearestNeighbors.custom_distance"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.KNearestNeighbors.custom_distance">[docs]</a>    <span class="k">def</span> <span class="nf">custom_distance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">point1</span><span class="p">,</span> <span class="n">point2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate the custom distance between two data points.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            point1 (list): The first data point.</span>
<span class="sd">            point2 (list): The second data point.</span>

<span class="sd">        Returns:</span>
<span class="sd">            float: The distance between the two points.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">distance</span> <span class="o">==</span> <span class="s1">&#39;EU&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">euclidean</span><span class="p">(</span><span class="n">point1</span><span class="o">=</span><span class="n">point1</span><span class="p">,</span> <span class="n">point2</span><span class="o">=</span><span class="n">point2</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">distance</span> <span class="o">==</span> <span class="s1">&#39;MA&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">manhattan</span><span class="p">(</span><span class="n">point1</span><span class="o">=</span><span class="n">point1</span><span class="p">,</span> <span class="n">point2</span><span class="o">=</span><span class="n">point2</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">distance</span> <span class="o">==</span> <span class="s1">&#39;MI&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">minkowski</span><span class="p">(</span><span class="n">point1</span><span class="o">=</span><span class="n">point1</span><span class="p">,</span> <span class="n">point2</span><span class="o">=</span><span class="n">point2</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">distance</span> <span class="o">==</span> <span class="s1">&#39;CH&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">chebyshev</span><span class="p">(</span><span class="n">point1</span><span class="o">=</span><span class="n">point1</span><span class="p">,</span> <span class="n">point2</span><span class="o">=</span><span class="n">point2</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">distance</span> <span class="o">==</span> <span class="s1">&#39;CO&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cosine</span><span class="p">(</span><span class="n">point1</span><span class="o">=</span><span class="n">point1</span><span class="p">,</span> <span class="n">point2</span><span class="o">=</span><span class="n">point2</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid distance algorithm. available are: &#39;EU&#39; (euclidean distance),&quot;</span>
                             <span class="s2">&quot; &#39;MA&#39; (manhattan distance), &#39;MI&#39;(minkowski distance), &#39;CH&#39; (chebyshev distance),&quot;</span>
                             <span class="s2">&quot;&#39;CO&#39; (cosine distance).&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="KNearestNeighbors.euclidean"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.KNearestNeighbors.euclidean">[docs]</a>    <span class="k">def</span> <span class="nf">euclidean</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">point1</span><span class="p">,</span> <span class="n">point2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate the Euclidean distance between two points.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            point1 (list): The first data point.</span>
<span class="sd">            point2 (list): The second data point.</span>

<span class="sd">        Returns:</span>
<span class="sd">            float: The Euclidean distance between the two points.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">distance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">point1</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">point2</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">distance</span></div>

<div class="viewcode-block" id="KNearestNeighbors.manhattan"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.KNearestNeighbors.manhattan">[docs]</a>    <span class="k">def</span> <span class="nf">manhattan</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">point1</span><span class="p">,</span> <span class="n">point2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate the Manhattan distance between two points.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            point1 (list): The first data point.</span>
<span class="sd">            point2 (list): The second data point.</span>

<span class="sd">        Returns:</span>
<span class="sd">            float: The Manhattan distance between the two points.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">distance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">point1</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">point2</span><span class="p">)))</span>

        <span class="k">return</span> <span class="n">distance</span></div>

<div class="viewcode-block" id="KNearestNeighbors.minkowski"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.KNearestNeighbors.minkowski">[docs]</a>    <span class="k">def</span> <span class="nf">minkowski</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">point1</span><span class="p">,</span> <span class="n">point2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate the Minkowski distance between two points.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            point1 (list): The first data point.</span>
<span class="sd">            point2 (list): The second data point.</span>

<span class="sd">        Returns:</span>
<span class="sd">            float: The Minkowski distance between the two points.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">distance</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">point1</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">point2</span><span class="p">))</span>
                           <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_value</span><span class="p">))</span> <span class="o">**</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_value</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">distance</span></div>

<div class="viewcode-block" id="KNearestNeighbors.chebyshev"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.KNearestNeighbors.chebyshev">[docs]</a>    <span class="k">def</span> <span class="nf">chebyshev</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">point1</span><span class="p">,</span> <span class="n">point2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate the Chebyshev distance between two points.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            point1 (list): The first data point.</span>
<span class="sd">            point2 (list): The second data point.</span>

<span class="sd">        Returns:</span>
<span class="sd">            float: The Chebyshev distance between the two points.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">distance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">point1</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">point2</span><span class="p">)))</span>

        <span class="k">return</span> <span class="n">distance</span></div>

<div class="viewcode-block" id="KNearestNeighbors.cosine"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.KNearestNeighbors.cosine">[docs]</a>    <span class="k">def</span> <span class="nf">cosine</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">point1</span><span class="p">,</span> <span class="n">point2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate the Cosine distance between two points.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            point1 (list): The first data point.</span>
<span class="sd">            point2 (list): The second data point.</span>

<span class="sd">        Returns:</span>
<span class="sd">            float: The Cosine distance between the two points.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">dot_product</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">point1</span><span class="p">,</span> <span class="n">point2</span><span class="p">)</span>
        <span class="n">norm_p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">point1</span><span class="p">)</span>
        <span class="n">norm_q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">point2</span><span class="p">)</span>
        <span class="n">distance</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="p">(</span><span class="n">dot_product</span> <span class="o">/</span> <span class="p">(</span><span class="n">norm_p</span> <span class="o">*</span> <span class="n">norm_q</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">distance</span></div>

<div class="viewcode-block" id="KNearestNeighbors.predict"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.KNearestNeighbors.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Make predictions for a list of data points.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            data (list): A list of data points to make predictions for.</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: Predictions for each data point.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">point_predict</span><span class="p">(</span><span class="n">point</span><span class="o">=</span><span class="n">point</span><span class="p">)</span> <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">predictions</span></div>

<div class="viewcode-block" id="KNearestNeighbors.point_predict"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.KNearestNeighbors.point_predict">[docs]</a>    <span class="k">def</span> <span class="nf">point_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">point</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predict the class or value of a single data point.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            point (list): A single data point.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int or float: The predicted class (for classification) or value (for regression).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">distances</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">custom_distance</span><span class="p">(</span><span class="n">point1</span><span class="o">=</span><span class="n">point</span><span class="p">,</span> <span class="n">point2</span><span class="o">=</span><span class="n">train_point</span><span class="p">)</span> <span class="k">for</span> <span class="n">train_point</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">]</span>
        <span class="n">k_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">distances</span><span class="p">)[:</span><span class="bp">self</span><span class="o">.</span><span class="n">num_neighbors</span><span class="p">]</span>
        <span class="n">k_nearest_labels</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">k_indices</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">algorithm</span> <span class="o">==</span> <span class="s1">&#39;classification&#39;</span><span class="p">:</span>
            <span class="n">most_common</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">k_nearest_labels</span><span class="p">)</span><span class="o">.</span><span class="n">most_common</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">most_common</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">algorithm</span> <span class="o">==</span> <span class="s1">&#39;regression&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">k_nearest_labels</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid algorithm. Supported values: &#39;classification&#39; or &#39;regression&#39;&quot;</span><span class="p">)</span></div></div>




<div class="viewcode-block" id="NaiveBayes"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.NaiveBayes">[docs]</a><span class="k">class</span> <span class="nc">NaiveBayes</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;classification&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes a NaiveBayes classifier/regressor.</span>

<span class="sd">        :param train_data: Input training data in the form of [(y1, [x11, x12, ..., x1n]), (y2, [x21, x22, x2n]), ...].</span>
<span class="sd">        :param algorithm: The type of algorithm, either &#39;classification&#39; or &#39;regression&#39; (default is &#39;classification&#39;).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">algorithm</span> <span class="o">=</span> <span class="n">algorithm</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">classes</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># For storing class means</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">variance</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># For storing class variances</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="NaiveBayes.train"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.NaiveBayes.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Trains the NaiveBayes model with the provided training data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">point</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">])</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">point</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">])</span>

        <span class="n">num_points</span><span class="p">,</span> <span class="n">num_features</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="p">),</span> <span class="n">num_features</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="p">),</span> <span class="n">num_features</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="bp">cls</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="p">):</span>
            <span class="n">feature_cls</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">labels</span> <span class="o">==</span> <span class="bp">cls</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">feature_cls</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">variance</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">feature_cls</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">prior</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">feature_cls</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">num_points</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span></div>

<div class="viewcode-block" id="NaiveBayes.likelihood"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.NaiveBayes.likelihood">[docs]</a>    <span class="k">def</span> <span class="nf">likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">variance</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the likelihood of the data given the class mean and variance using Gaussian distribution.</span>

<span class="sd">        :param data: The data point for which to calculate the likelihood.</span>
<span class="sd">        :param mean: The mean of the class.</span>
<span class="sd">        :param variance: The variance of the class.</span>
<span class="sd">        :return: The likelihood of the data point.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-4</span>
        <span class="n">coefficient</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">variance</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span>

        <span class="n">exponent</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">((</span><span class="n">data</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">variance</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)))</span>
        <span class="n">likelihood</span> <span class="o">=</span> <span class="n">coefficient</span> <span class="o">*</span> <span class="n">exponent</span>

        <span class="k">return</span> <span class="n">likelihood</span></div>

<div class="viewcode-block" id="NaiveBayes.predict"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.NaiveBayes.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predicts the labels or values of the given features.</span>

<span class="sd">        :param features: The features to make predictions for.</span>
<span class="sd">        :return: Predicted labels or values for the features.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">algorithm</span> <span class="o">==</span> <span class="s1">&#39;classification&#39;</span><span class="p">:</span>

            <span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">point_predict</span><span class="p">(</span><span class="n">feature</span><span class="o">=</span><span class="n">feature</span><span class="p">)</span> <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">features</span><span class="p">]</span>

            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">algorithm</span> <span class="o">==</span> <span class="s1">&#39;regression&#39;</span><span class="p">:</span>

            <span class="n">num_samples</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">features</span><span class="o">.</span><span class="n">shape</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>

                <span class="n">posteriors</span> <span class="o">=</span> <span class="p">[]</span>

                <span class="k">for</span> <span class="n">label_index</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="p">):</span>

                    <span class="n">prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">==</span> <span class="n">label</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
                    <span class="n">pairs</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">[</span><span class="n">label_index</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">variance</span><span class="p">[</span><span class="n">label_index</span><span class="p">])</span>

                    <span class="n">likelihood</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">variance</span><span class="o">=</span><span class="n">variance</span><span class="p">))</span>
                                         <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">variance</span> <span class="ow">in</span> <span class="n">pairs</span><span class="p">])</span>

                    <span class="n">posteriors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prior</span> <span class="o">+</span> <span class="n">likelihood</span><span class="p">)</span>

                <span class="n">predictions</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">posteriors</span><span class="p">)]</span>

            <span class="k">return</span> <span class="n">predictions</span>

        <span class="k">else</span><span class="p">:</span>

            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid algorithm. Supported values: &#39;classification&#39; or &#39;regression&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="NaiveBayes.point_predict"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.NaiveBayes.point_predict">[docs]</a>    <span class="k">def</span> <span class="nf">point_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predicts the label or value for a single data point (feature).</span>

<span class="sd">        :param feature: The data point (feature) to make a prediction for.</span>
<span class="sd">        :return: The predicted label or value for the data point.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">posteriors</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="bp">cls</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="p">):</span>

            <span class="n">prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
            <span class="n">posterior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">probability_density</span><span class="p">(</span><span class="n">class_index</span><span class="o">=</span><span class="n">index</span><span class="p">,</span> <span class="n">feature</span><span class="o">=</span><span class="n">feature</span><span class="p">)))</span>
            <span class="n">posterior</span> <span class="o">=</span> <span class="n">posterior</span> <span class="o">+</span> <span class="n">prior</span>

            <span class="n">posteriors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">posteriors</span><span class="p">)]</span></div>

<div class="viewcode-block" id="NaiveBayes.probability_density"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.NaiveBayes.probability_density">[docs]</a>    <span class="k">def</span> <span class="nf">probability_density</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">class_index</span><span class="p">,</span> <span class="n">feature</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the probability density of a feature for a specific class.</span>

<span class="sd">        :param class_index: The index of the class.</span>
<span class="sd">        :param feature: The feature for which to calculate the probability density.</span>
<span class="sd">        :return: The probability density of the feature for the specified class.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">[</span><span class="n">class_index</span><span class="p">]</span>
        <span class="n">var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">variance</span><span class="p">[</span><span class="n">class_index</span><span class="p">]</span>

        <span class="n">numerator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">feature</span> <span class="o">-</span> <span class="n">mean</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">var</span><span class="p">))</span>
        <span class="n">denominator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">var</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">numerator</span> <span class="o">/</span> <span class="n">denominator</span></div></div>



<div class="viewcode-block" id="PrincipalComponentAnalysis"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.PrincipalComponentAnalysis">[docs]</a><span class="k">class</span> <span class="nc">PrincipalComponentAnalysis</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">num_components</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes a Principal Component Analysis (PCA) object.</span>

<span class="sd">        :param features: Input features as a 2D array.</span>
<span class="sd">        :param num_components: Number of principal components to retain.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_components</span> <span class="o">=</span> <span class="n">num_components</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">components</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="PrincipalComponentAnalysis.train"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.PrincipalComponentAnalysis.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Performs PCA training on the input features.</span>
<span class="sd">        Computes principal components and updates the mean.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span>

        <span class="n">covariance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">features</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

        <span class="n">eigenvectors</span><span class="p">,</span> <span class="n">eigenvalues</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">covariance</span><span class="p">)</span>

        <span class="n">eigenvectors</span> <span class="o">=</span> <span class="n">eigenvectors</span><span class="o">.</span><span class="n">T</span>

        <span class="n">index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">eigenvalues</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">eigenvalues</span> <span class="o">=</span> <span class="n">eigenvalues</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="n">eigenvectors</span> <span class="o">=</span> <span class="n">eigenvectors</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">components</span> <span class="o">=</span> <span class="n">eigenvectors</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">num_components</span><span class="p">]</span></div>

<div class="viewcode-block" id="PrincipalComponentAnalysis.transform"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.PrincipalComponentAnalysis.transform">[docs]</a>    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Transforms the input features using the learned principal components.</span>

<span class="sd">        :return: Transformed features with reduced dimensions.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span>
        <span class="n">transformed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">components</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">transformed</span></div></div>





<div class="viewcode-block" id="SupportVectorMachines"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.SupportVectorMachines">[docs]</a><span class="k">class</span> <span class="nc">SupportVectorMachines</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Support Vector Machines (SVM) classifier.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    - training_data: List of training data points in the form [(y, [x1, x2, ..., xn]), ...].</span>
<span class="sd">    - optimization_algorithm: Optimization algorithm to use (&#39;GD&#39; for Gradient Descent,</span>
<span class="sd">      &#39;SMO&#39; for Sequential Minimal Optimization).</span>

<span class="sd">    - kernel: Kernel function to use (&#39;linear&#39;, &#39;quadratic&#39;, &#39;gaussian&#39;).</span>
<span class="sd">    - learning_rate: Learning rate for GD (default is 1e-4).</span>
<span class="sd">    - lam: Regularization parameter (default is 1e-4).</span>
<span class="sd">    - max_iteration: Maximum number of iterations for training (default is 1000).</span>
<span class="sd">    - threshold: Convergence threshold for GD (default is 1e-5).</span>
<span class="sd">    - regularization_parameter: Regularization parameter for SMO (default is 1).</span>
<span class="sd">    - epsilon: Convergence tolerance for SMO (default is 1e-4).</span>
<span class="sd">    - sigma: Sigma value for the Gaussian kernel (default is -0.1).</span>

<span class="sd">    The training_data must have the structure:</span>
<span class="sd">    [(y1, [x11, x12, ..., x1n]), (y2, [x21, x22, x2n]), ..., (ym, [xm1, xm2, ..., xmn])]</span>

<span class="sd">    Methods:</span>
<span class="sd">    - train: Train the SVM model using the selected optimization algorithm.</span>
<span class="sd">    - predict: Make predictions on input data points after training.</span>

<span class="sd">    Note: Call the &#39;train&#39; method before making predictions.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">optimization_algorithm</span><span class="o">=</span><span class="s1">&#39;GD&#39;</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
                 <span class="n">max_iteration</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">regularization_parameter</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=-</span><span class="mf">0.1</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">training_data</span> <span class="o">=</span> <span class="n">training_data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimization_algorithm</span> <span class="o">=</span> <span class="n">optimization_algorithm</span>

        <span class="n">kernels</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;linear&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_kernel</span><span class="p">,</span>
            <span class="s1">&#39;quadratic&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">quadratic_kernel</span><span class="p">,</span>
            <span class="s1">&#39;gaussian&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">gaussian_kernel</span>
        <span class="p">}</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">kernels</span><span class="p">[</span><span class="n">kernel</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lam</span> <span class="o">=</span> <span class="n">lam</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iteration</span> <span class="o">=</span> <span class="n">max_iteration</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regularization_parameter</span> <span class="o">=</span> <span class="n">regularization_parameter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span> <span class="o">=</span> <span class="n">sigma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">algorithms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;SGD&#39;</span><span class="p">,</span> <span class="s1">&#39;SMO&#39;</span><span class="p">]</span>

<div class="viewcode-block" id="SupportVectorMachines.train"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.SupportVectorMachines.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train the Support Vector Machines (SVM) model using the specified optimization algorithm.</span>

<span class="sd">        This method iteratively updates the weights and bias to find the optimal decision boundary.</span>

<span class="sd">        Returns:</span>
<span class="sd">        None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Training data</span>
        <span class="n">points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_data</span><span class="p">])</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_data</span><span class="p">])</span>

        <span class="c1"># Initialize weights and bias</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="n">num_iter_count</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_algorithm</span> <span class="o">==</span> <span class="s1">&#39;GD&#39;</span><span class="p">:</span>
            <span class="c1"># Train using Gradient Descent (GD)</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iteration</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">point</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">points</span><span class="p">):</span>
                    <span class="n">error</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">point</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">))</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>
                    <span class="k">if</span> <span class="n">error</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="c1"># Update weights and bias</span>
                        <span class="n">d_weights</span><span class="p">,</span> <span class="n">d_bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">der_hinge_loss</span><span class="p">(</span><span class="n">error</span><span class="p">,</span> <span class="n">point</span><span class="p">,</span> <span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">d_weights</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">d_bias</span>
                    <span class="n">num_iter_count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimization_algorithm</span> <span class="o">==</span> <span class="s1">&#39;SMO&#39;</span><span class="p">:</span>
            <span class="c1"># Train using Sequential Minimal Optimization (SMO)</span>
            <span class="c1"># Add the SMO training logic here</span>
            <span class="k">pass</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>  <span class="c1"># Save the learned weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>  <span class="c1"># Save the learned bias</span></div>

<div class="viewcode-block" id="SupportVectorMachines.der_hinge_loss"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.SupportVectorMachines.der_hinge_loss">[docs]</a>    <span class="k">def</span> <span class="nf">der_hinge_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">error</span><span class="p">,</span> <span class="n">point</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>

        <span class="k">if</span> <span class="n">error</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">d_weights</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">lam</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>

            <span class="n">d_bias</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">d_weights</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">lam</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">-</span> <span class="p">(</span><span class="n">point</span> <span class="o">*</span> <span class="n">label</span><span class="p">)</span>

            <span class="n">d_bias</span> <span class="o">=</span> <span class="o">-</span> <span class="n">label</span>

        <span class="k">return</span> <span class="n">d_weights</span><span class="p">,</span> <span class="n">d_bias</span></div>

<div class="viewcode-block" id="SupportVectorMachines.linear_kernel"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.SupportVectorMachines.linear_kernel">[docs]</a>    <span class="k">def</span> <span class="nf">linear_kernel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">point1</span><span class="p">,</span> <span class="n">point2</span><span class="p">):</span>

        <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

        <span class="n">calc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">point1</span><span class="p">,</span> <span class="n">point2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">calc</span></div>

<div class="viewcode-block" id="SupportVectorMachines.quadratic_kernel"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.SupportVectorMachines.quadratic_kernel">[docs]</a>    <span class="k">def</span> <span class="nf">quadratic_kernel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">point1</span><span class="p">,</span> <span class="n">point2</span><span class="p">):</span>

        <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

        <span class="n">calc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear_kernel</span><span class="p">(</span><span class="n">point1</span><span class="p">,</span> <span class="n">point2</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">calc</span></div>

<div class="viewcode-block" id="SupportVectorMachines.gaussian_kernel"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.SupportVectorMachines.gaussian_kernel">[docs]</a>    <span class="k">def</span> <span class="nf">gaussian_kernel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">point1</span><span class="p">,</span> <span class="n">point2</span><span class="p">):</span>

        <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

        <span class="n">calc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">point1</span> <span class="o">-</span> <span class="n">point2</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">calc</span></div>

<div class="viewcode-block" id="SupportVectorMachines.random_num"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.SupportVectorMachines.random_num">[docs]</a>    <span class="k">def</span> <span class="nf">random_num</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>

        <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

        <span class="n">lst</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">z</span><span class="p">))</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">z</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">lst</span><span class="p">)</span></div>

<div class="viewcode-block" id="SupportVectorMachines.weight_calculator"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.SupportVectorMachines.weight_calculator">[docs]</a>    <span class="k">def</span> <span class="nf">weight_calculator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">point</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>

        <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

        <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">point</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">label</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">weights</span></div>

<div class="viewcode-block" id="SupportVectorMachines.bias_calculator"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.SupportVectorMachines.bias_calculator">[docs]</a>    <span class="k">def</span> <span class="nf">bias_calculator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">point</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>

        <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

        <span class="n">bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">label</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">point</span><span class="p">,</span> <span class="n">weights</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">bias</span></div>

<div class="viewcode-block" id="SupportVectorMachines.prediction_error"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.SupportVectorMachines.prediction_error">[docs]</a>    <span class="k">def</span> <span class="nf">prediction_error</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">point_k</span><span class="p">,</span> <span class="n">label_k</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">bias</span><span class="p">):</span>

        <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

        <span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">point_k</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span> <span class="o">+</span> <span class="n">bias</span><span class="p">)</span> <span class="o">-</span> <span class="n">label_k</span>

        <span class="k">return</span> <span class="n">error</span></div>

<div class="viewcode-block" id="SupportVectorMachines.compute_l_h"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.SupportVectorMachines.compute_l_h">[docs]</a>    <span class="k">def</span> <span class="nf">compute_l_h</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">alpha_pj</span><span class="p">,</span> <span class="n">alpha_pi</span><span class="p">,</span> <span class="n">label_j</span><span class="p">,</span> <span class="n">label_i</span><span class="p">):</span>

        <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

        <span class="k">if</span> <span class="n">label_i</span> <span class="o">!=</span> <span class="n">label_j</span><span class="p">:</span>

            <span class="n">bounds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">alpha_pj</span> <span class="o">-</span> <span class="n">alpha_pi</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">c</span> <span class="o">-</span> <span class="n">alpha_pi</span> <span class="o">+</span> <span class="n">alpha_pj</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">bounds</span>

        <span class="k">else</span><span class="p">:</span>

            <span class="n">bounds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">alpha_pj</span> <span class="o">+</span> <span class="n">alpha_pi</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">c</span> <span class="o">-</span> <span class="n">alpha_pi</span> <span class="o">+</span> <span class="n">alpha_pj</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">bounds</span></div>

<div class="viewcode-block" id="SupportVectorMachines.predict"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.SupportVectorMachines.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">points</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Make predictions using the trained SVM model.</span>

<span class="sd">        Parameters:</span>
<span class="sd">        - points: List of data points to make predictions on.</span>

<span class="sd">        Returns:</span>
<span class="sd">        List of predictions (-1 or 1) for each input point.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">points</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

            <span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">point</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span> <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="n">points</span><span class="p">]</span>

            <span class="k">return</span> <span class="n">predictions</span>

        <span class="k">else</span><span class="p">:</span>

            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Model has not been trained. You need to call the &#39;train&#39; method first.&quot;</span><span class="p">)</span></div></div>



<div class="viewcode-block" id="GradientBoosting"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.GradientBoosting">[docs]</a><span class="k">class</span> <span class="nc">GradientBoosting</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A gradient boosting classifier.</span>

<span class="sd">    Args:</span>
<span class="sd">    train_data (list): Training data in the form [(label, features), ...].</span>
<span class="sd">    min_points (int): Minimum number of data points for a node (default is 2).</span>
<span class="sd">    max_depth (int): Maximum depth of decision trees (default is 2).</span>
<span class="sd">    num_features (int): Number of features to consider for each tree (default is None).</span>
<span class="sd">    num_trees (int): Number of boosting iterations (default is 10).</span>
<span class="sd">    curr_depth (int): Current depth during training (default is 0).</span>
<span class="sd">    threshold (float): Classification threshold (default is 0.5).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">min_points</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_trees</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                 <span class="n">curr_depth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span> <span class="o">=</span> <span class="n">max_depth</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span> <span class="o">=</span> <span class="n">num_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_points</span> <span class="o">=</span> <span class="n">min_points</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_trees</span> <span class="o">=</span> <span class="n">num_trees</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">curr_depth</span> <span class="o">=</span> <span class="n">curr_depth</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trees</span> <span class="o">=</span> <span class="p">[]</span>

<div class="viewcode-block" id="GradientBoosting.train"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.GradientBoosting.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train the gradient boosting classifier.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="n">point</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">]</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">point</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">]</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">[(</span><span class="n">label</span><span class="p">,</span> <span class="n">point</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">point</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">features</span><span class="p">)]</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_trees</span><span class="p">):</span>

            <span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTree</span><span class="p">(</span><span class="n">train_data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
                                <span class="n">min_points</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">min_points</span><span class="p">,</span>
                                <span class="n">max_depth</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span><span class="p">,</span>
                                <span class="n">num_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_features</span><span class="p">,</span>
                                <span class="n">curr_depth</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">curr_depth</span>
                                <span class="p">)</span>

            <span class="n">tree</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            <span class="n">predicted</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span> <span class="o">-</span> <span class="n">predicted</span><span class="p">]</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">trees</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tree</span><span class="p">)</span></div>

<div class="viewcode-block" id="GradientBoosting.predict"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.GradientBoosting.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Make predictions using the trained gradient boosting classifier.</span>

<span class="sd">        Args:</span>
<span class="sd">        features (list): List of feature vectors for prediction.</span>

<span class="sd">        Returns:</span>
<span class="sd">        numpy.ndarray: Predicted labels (0 or 1) for each input feature vector.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Initialize a list to store the prediction value for each tree</span>
        <span class="n">trees_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trees</span><span class="p">)))</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">tree</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trees</span><span class="p">):</span>
            <span class="n">trees_predictions</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

        <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">trees_predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="n">predictions</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">predictions</span></div></div>



<div class="viewcode-block" id="GaussianMixtureModel"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.GaussianMixtureModel">[docs]</a><span class="k">class</span> <span class="nc">GaussianMixtureModel</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">num_clusters</span><span class="p">,</span> <span class="n">means</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">covariances</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">coefficients</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                 <span class="n">threshold</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize a Gaussian Mixture Model.</span>

<span class="sd">        :param train_data: Training data as a list of data points.</span>
<span class="sd">        :param num_clusters: Number of clusters in the model.</span>
<span class="sd">        :param means: Initial means for clusters (default is None).</span>
<span class="sd">        :param covariances: Initial covariances for clusters (default is None).</span>
<span class="sd">        :param coefficients: Initial coefficients for clusters (default is None).</span>
<span class="sd">        :param max_iter: Maximum number of iterations during training (default is 1000).</span>
<span class="sd">        :param threshold: Convergence threshold for log-likelihood (default is 1e-4).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_clusters</span> <span class="o">=</span> <span class="n">num_clusters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">means</span> <span class="o">=</span> <span class="n">means</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">covariances</span> <span class="o">=</span> <span class="n">covariances</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coefficients</span> <span class="o">=</span> <span class="n">coefficients</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="n">max_iter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">responsibilities</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loglikelihood</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loglikelihood_trace</span> <span class="o">=</span> <span class="p">[]</span>

<div class="viewcode-block" id="GaussianMixtureModel.train"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.GaussianMixtureModel.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train the Gaussian Mixture Model using the provided data and parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">means</span><span class="p">:</span>

            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
            <span class="n">random_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_clusters</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">means</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">random_indices</span><span class="p">]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">covariances</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">covariances</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_clusters</span><span class="p">)]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">coefficients</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coefficients</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_clusters</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_clusters</span>

        <span class="n">num_point</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">responsibilities</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_point</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_clusters</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loglikelihood</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_loglikelihood</span><span class="p">(</span>
            <span class="n">data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">,</span>
            <span class="n">coefficients</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">coefficients</span><span class="p">,</span>
            <span class="n">means</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">means</span><span class="p">,</span>
            <span class="n">covariances</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">covariances</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loglikelihood_trace</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">loglikelihood</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">):</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">responsibilities</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_response</span><span class="p">(</span>
                <span class="n">data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">,</span>
                <span class="n">coefficients</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">coefficients</span><span class="p">,</span>
                <span class="n">means</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">means</span><span class="p">,</span>
                <span class="n">covariances</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">covariances</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">counts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">soft_counts</span><span class="p">(</span>
                <span class="n">responsibilities</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">responsibilities</span>
            <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">coefficients</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_coefficients</span><span class="p">(</span>
                <span class="n">counts</span><span class="o">=</span><span class="n">counts</span>
            <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">means</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_means</span><span class="p">(</span>
                <span class="n">data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">,</span>
                <span class="n">responsibilities</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">responsibilities</span><span class="p">,</span>
                <span class="n">counts</span><span class="o">=</span><span class="n">counts</span>
            <span class="p">)</span>

            <span class="n">covariances</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_covariances</span><span class="p">(</span>
                <span class="n">data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">,</span>
                <span class="n">responsibilities</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">responsibilities</span><span class="p">,</span>
                <span class="n">counts</span><span class="o">=</span><span class="n">counts</span><span class="p">,</span>
                <span class="n">means</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">means</span>
            <span class="p">)</span>

            <span class="n">l_loglikelihood</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_loglikelihood</span><span class="p">(</span>
                <span class="n">data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">,</span>
                <span class="n">coefficients</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">coefficients</span><span class="p">,</span>
                <span class="n">means</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">means</span><span class="p">,</span>
                <span class="n">covariances</span><span class="o">=</span><span class="n">covariances</span>
            <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">loglikelihood_trace</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">l_loglikelihood</span><span class="p">)</span></div>


<div class="viewcode-block" id="GaussianMixtureModel.compute_loglikelihood"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.GaussianMixtureModel.compute_loglikelihood">[docs]</a>    <span class="k">def</span> <span class="nf">compute_loglikelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">coefficients</span><span class="p">,</span> <span class="n">means</span><span class="p">,</span> <span class="n">covariances</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate the log-likelihood of the data given the model parameters.</span>

<span class="sd">        :param data: Data points for log-likelihood calculation.</span>
<span class="sd">        :param coefficients: Cluster coefficients.</span>
<span class="sd">        :param means: Cluster means.</span>
<span class="sd">        :param covariances: Cluster covariances.</span>

<span class="sd">        :return: Log-likelihood of the data.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">num_clusters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">means</span><span class="p">)</span>
        <span class="n">num_dimension</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="n">loglikelihood</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>

            <span class="n">results</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_clusters</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_clusters</span><span class="p">):</span>

                <span class="n">delta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">point</span><span class="p">)</span> <span class="o">-</span> <span class="n">means</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">exponent_term</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">delta</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">covariances</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="n">delta</span><span class="p">))</span>

                <span class="n">results</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">coefficients</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="n">results</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">1</span> <span class="o">/</span> <span class="mf">2.</span> <span class="o">*</span> <span class="p">(</span><span class="n">num_dimension</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">det</span><span class="p">(</span><span class="n">covariances</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span> <span class="o">+</span> <span class="n">exponent_term</span><span class="p">)</span>

            <span class="n">loglikelihood</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_sum_exp</span><span class="p">(</span><span class="n">results</span><span class="o">=</span><span class="n">results</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loglikelihood</span></div>

<div class="viewcode-block" id="GaussianMixtureModel.log_sum_exp"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.GaussianMixtureModel.log_sum_exp">[docs]</a>    <span class="k">def</span> <span class="nf">log_sum_exp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">results</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate the log of the sum of exponentials.</span>

<span class="sd">        :param results: List of results to calculate the log-sum-exp for.</span>

<span class="sd">        :return: Log of the sum of exponentials.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">loglikelihood</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">results</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">results</span><span class="p">))))</span>

        <span class="k">return</span> <span class="n">loglikelihood</span></div>

<div class="viewcode-block" id="GaussianMixtureModel.compute_response"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.GaussianMixtureModel.compute_response">[docs]</a>    <span class="k">def</span> <span class="nf">compute_response</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">coefficients</span><span class="p">,</span> <span class="n">means</span><span class="p">,</span> <span class="n">covariances</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the responsibilities for each data point.</span>

<span class="sd">        :param data: Data points.</span>
<span class="sd">        :param coefficients: Cluster coefficients.</span>
<span class="sd">        :param means: Cluster means.</span>
<span class="sd">        :param covariances: Cluster covariances.</span>

<span class="sd">        :return: Responsibilities for each data point.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">num_point</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">num_clusters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">means</span><span class="p">)</span>
        <span class="n">responsibilities</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_point</span><span class="p">,</span> <span class="n">num_clusters</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_point</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_clusters</span><span class="p">):</span>
                <span class="n">responsibilities</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">coefficients</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">means</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">covariances</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>

        <span class="n">row_sums</span> <span class="o">=</span> <span class="n">responsibilities</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
        <span class="n">resp</span> <span class="o">=</span> <span class="n">responsibilities</span> <span class="o">/</span> <span class="n">row_sums</span>

        <span class="k">return</span> <span class="n">resp</span></div>

<div class="viewcode-block" id="GaussianMixtureModel.soft_counts"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.GaussianMixtureModel.soft_counts">[docs]</a>    <span class="k">def</span> <span class="nf">soft_counts</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">responsibilities</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate soft counts based on responsibilities.</span>

<span class="sd">        :param responsibilities: Responsibilities for data points.</span>

<span class="sd">        :return: Soft counts for each cluster.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">responsibilities</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">counts</span></div>

<div class="viewcode-block" id="GaussianMixtureModel.compute_coefficients"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.GaussianMixtureModel.compute_coefficients">[docs]</a>    <span class="k">def</span> <span class="nf">compute_coefficients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">counts</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate cluster coefficients based on soft counts.</span>

<span class="sd">        :param counts: Soft counts for each cluster.</span>

<span class="sd">        :return: Cluster coefficients.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">num_clusters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">counts</span><span class="p">)</span>
        <span class="n">coefficients</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_clusters</span>

        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_clusters</span><span class="p">):</span>

            <span class="n">coefficients</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">counts</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">coefficients</span></div>

<div class="viewcode-block" id="GaussianMixtureModel.compute_means"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.GaussianMixtureModel.compute_means">[docs]</a>    <span class="k">def</span> <span class="nf">compute_means</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">responsibilities</span><span class="p">,</span> <span class="n">counts</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate updated means for clusters.</span>

<span class="sd">        :param data: Data points.</span>
<span class="sd">        :param responsibilities: Responsibilities for data points.</span>
<span class="sd">        :param counts: Soft counts for each cluster.</span>

<span class="sd">        :return: Updated cluster means.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">num_clusters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">counts</span><span class="p">)</span>
        <span class="n">num_data</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">means</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]))]</span> <span class="o">*</span> <span class="n">num_clusters</span>

        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_clusters</span><span class="p">):</span>

            <span class="n">weighted_sum</span> <span class="o">=</span> <span class="mf">0.</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_data</span><span class="p">):</span>
                <span class="n">weighted_sum</span> <span class="o">+=</span> <span class="n">responsibilities</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">means</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">weighted_sum</span> <span class="o">/</span> <span class="n">counts</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">means</span></div>

<div class="viewcode-block" id="GaussianMixtureModel.compute_covariances"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.GaussianMixtureModel.compute_covariances">[docs]</a>    <span class="k">def</span> <span class="nf">compute_covariances</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">responsibilities</span><span class="p">,</span> <span class="n">counts</span><span class="p">,</span> <span class="n">means</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate updated covariances for clusters.</span>

<span class="sd">        :param data: Data points.</span>
<span class="sd">        :param responsibilities: Responsibilities for data points.</span>
<span class="sd">        :param counts: Soft counts for each cluster.</span>
<span class="sd">        :param means: Cluster means.</span>

<span class="sd">        :return: Updated cluster covariances.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">num_clusters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">counts</span><span class="p">)</span>
        <span class="n">num_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">num_data</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">covariances</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_dim</span><span class="p">,</span> <span class="n">num_dim</span><span class="p">))]</span> <span class="o">*</span> <span class="n">num_clusters</span>

        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_clusters</span><span class="p">):</span>

            <span class="n">weighted_sum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_dim</span><span class="p">,</span> <span class="n">num_dim</span><span class="p">))</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_data</span><span class="p">):</span>

                <span class="n">weighted_sum</span> <span class="o">+=</span> <span class="n">responsibilities</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">means</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">means</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>

            <span class="n">covariances</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">weighted_sum</span> <span class="o">/</span> <span class="n">counts</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">covariances</span></div></div>





<div class="viewcode-block" id="SingularValueDecomposition"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.SingularValueDecomposition">[docs]</a><span class="k">class</span> <span class="nc">SingularValueDecomposition</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">num_dimension</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span>  <span class="c1"># the input matrix. can be a nested list,</span>
        <span class="c1"># which will be converted to a matrix during the process</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_dimension</span> <span class="o">=</span> <span class="n">num_dimension</span>  <span class="c1"># number of dimensions to return after processing the input data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">U</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># The left singular vectors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">S</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># The singular values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Vt</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># The transpose of the right singular vectors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">variance</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Proportion of total variance explained</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">t_matrix</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># transformed matrix</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Singular Value Decomposition (SVD) for dimensionality reduction.</span>

<span class="sd">        Args:</span>
<span class="sd">            data (list or numpy.ndarray): Input data in the form of a nested list or a numpy array.</span>
<span class="sd">            num_dimension (int): Number of dimensions to return after processing the input data.</span>

<span class="sd">        Attributes:</span>
<span class="sd">            data: The input matrix, which can be a nested list or a numpy array.</span>
<span class="sd">            num_dimension: The number of dimensions to return after processing the input data.</span>
<span class="sd">            U: The left singular vectors.</span>
<span class="sd">            S: The singular values.</span>
<span class="sd">            Vt: The transpose of the right singular vectors.</span>
<span class="sd">            variance: Proportion of total variance explained.</span>
<span class="sd">            t_matrix: Transformed matrix with reduced dimensions.</span>
<span class="sd">        &quot;&quot;&quot;</span>


<div class="viewcode-block" id="SingularValueDecomposition.matrix_decomposer"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.SingularValueDecomposition.matrix_decomposer">[docs]</a>    <span class="k">def</span> <span class="nf">matrix_decomposer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">matrix</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform SVD decomposition on the input matrix.</span>

<span class="sd">        Args:</span>
<span class="sd">            matrix (numpy.ndarray): Input matrix.</span>

<span class="sd">        Returns:</span>
<span class="sd">            left_singular_vector (numpy.ndarray): The left singular vectors.</span>
<span class="sd">            singular_values (numpy.ndarray): The singular values.</span>
<span class="sd">            t_right_singular_vectors (numpy.ndarray): The transpose of the right singular vectors.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># using nampy.linalg.svd to calculate all three returned matrices</span>

        <span class="n">left_singular_vector</span><span class="p">,</span> <span class="n">singular_values</span><span class="p">,</span> <span class="n">t_right_singular_vectors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span>
            <span class="n">matrix</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">compute_uv</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">left_singular_vector</span><span class="p">,</span> <span class="n">singular_values</span><span class="p">,</span> <span class="n">t_right_singular_vectors</span></div>

<div class="viewcode-block" id="SingularValueDecomposition.dimension_reducer"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.SingularValueDecomposition.dimension_reducer">[docs]</a>    <span class="k">def</span> <span class="nf">dimension_reducer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">left_singular_vector</span><span class="p">,</span> <span class="n">singular_values</span><span class="p">,</span> <span class="n">t_right_singular_vectors</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Reduce dimensions of the decomposed matrices.</span>

<span class="sd">        Args:</span>
<span class="sd">            left_singular_vector (numpy.ndarray): The left singular vectors.</span>
<span class="sd">            singular_values (numpy.ndarray): The singular values.</span>
<span class="sd">            t_right_singular_vectors (numpy.ndarray): The transpose of the right singular vectors.</span>

<span class="sd">        Returns:</span>
<span class="sd">            k_left_singular_vector (numpy.ndarray): Reduced left singular vectors.</span>
<span class="sd">            k_singular_matrix (numpy.ndarray): Reduced singular values as a diagonal matrix.</span>
<span class="sd">            k_right_singular_vectors (numpy.ndarray): Reduced transpose of right singular vectors.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Reduce the dimensions of left_singular_vector</span>
        <span class="n">k_left_singular_vector</span> <span class="o">=</span> <span class="n">left_singular_vector</span><span class="p">[:,</span> <span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">num_dimension</span><span class="p">]</span>

        <span class="c1"># Create a diagonal matrix using singular values and truncate it to the first num_dimension values</span>
        <span class="n">k_singular_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">singular_values</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">num_dimension</span><span class="p">])</span>

        <span class="c1"># Reduce the dimensions of t_right_singular_vectors</span>
        <span class="n">k_right_singular_vectors</span> <span class="o">=</span> <span class="n">t_right_singular_vectors</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">num_dimension</span><span class="p">,</span> <span class="p">:]</span>

        <span class="k">return</span> <span class="n">k_left_singular_vector</span><span class="p">,</span> <span class="n">k_singular_matrix</span><span class="p">,</span> <span class="n">k_right_singular_vectors</span></div>



<div class="viewcode-block" id="SingularValueDecomposition.matrix_reconstructor"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.SingularValueDecomposition.matrix_reconstructor">[docs]</a>    <span class="k">def</span> <span class="nf">matrix_reconstructor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k_left_singular_vector</span><span class="p">,</span> <span class="n">k_singular_matrix</span><span class="p">,</span> <span class="n">k_right_singular_vectors</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Reconstruct the original matrix from reduced dimensions.</span>

<span class="sd">        Args:</span>
<span class="sd">            k_left_singular_vector (numpy.ndarray): Reduced left singular vectors.</span>
<span class="sd">            k_singular_matrix (numpy.ndarray): Reduced singular values as a diagonal matrix.</span>
<span class="sd">            k_right_singular_vectors (numpy.ndarray): Reduced transpose of right singular vectors.</span>

<span class="sd">        Returns:</span>
<span class="sd">            reconstructed_matrix (numpy.ndarray): Reconstructed matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># reconstruct the matrix using this formula: A = U * S * Vt</span>
        <span class="n">reconstructed_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">k_left_singular_vector</span><span class="p">,</span> <span class="n">k_singular_matrix</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">k_right_singular_vectors</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">reconstructed_matrix</span></div>




<div class="viewcode-block" id="SingularValueDecomposition.transform"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.SingularValueDecomposition.transform">[docs]</a>    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform dimensionality reduction and reconstruction in a single step.</span>

<span class="sd">        Returns:</span>
<span class="sd">            reconstructed_matrix (numpy.ndarray): Transformed matrix with reduced dimensions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># check the type of the input data</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>  <span class="c1"># converts the input data to a matrix for further calculations</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The input must be in form numpy.ndarray or a nested list of points&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_dimension</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Please define the number of dimensions (num_dimension=?)of the output matrix.&quot;</span><span class="p">)</span>

        <span class="c1"># call matrix_decomposer to decompose the input data(matrix)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">U</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">S</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Vt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matrix_decomposer</span><span class="p">(</span><span class="n">matrix</span><span class="o">=</span><span class="n">matrix</span><span class="p">)</span>

        <span class="c1"># call dimension_reducer  to reduce dimensions of the decomposed vectors</span>
        <span class="n">k_left_singular_vector</span><span class="p">,</span> <span class="n">k_singular_matrix</span><span class="p">,</span> <span class="n">k_right_singular_vectors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dimension_reducer</span><span class="p">(</span>
            <span class="n">left_singular_vector</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">U</span><span class="p">,</span>
            <span class="n">singular_values</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">S</span><span class="p">,</span>
            <span class="n">t_right_singular_vectors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">Vt</span>
        <span class="p">)</span>

        <span class="c1"># call matrix_reconstructor to combine the decomposed vectors to build the dimension-reduced matrix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">t_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matrix_reconstructor</span><span class="p">(</span>
            <span class="n">k_left_singular_vector</span><span class="o">=</span><span class="n">k_left_singular_vector</span><span class="p">,</span>
            <span class="n">k_singular_matrix</span><span class="o">=</span><span class="n">k_singular_matrix</span><span class="p">,</span>
            <span class="n">k_right_singular_vectors</span><span class="o">=</span><span class="n">k_right_singular_vectors</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">variance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">variance_explained</span><span class="p">(</span>
            <span class="n">singular_values</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">S</span><span class="p">,</span>
            <span class="n">num_dimension</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_dimension</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">t_matrix</span></div>



<div class="viewcode-block" id="SingularValueDecomposition.variance_explained"><a class="viewcode-back" href="../../smartsolve.html#smartsolve.models.SingularValueDecomposition.variance_explained">[docs]</a>    <span class="k">def</span> <span class="nf">variance_explained</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">singular_values</span><span class="p">,</span> <span class="n">num_dimension</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate the variance explained by the first num_dimensions singular values.</span>

<span class="sd">        Args:</span>
<span class="sd">            singular_values (numpy.ndarray): The singular values.</span>
<span class="sd">            num_dimension (int): Number of dimensions to consider.</span>

<span class="sd">        Returns:</span>
<span class="sd">            variance_explained (float): Proportion of total variance explained.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">squared_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">singular_values</span><span class="p">[:</span><span class="n">num_dimension</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">sum_all_squared_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">singular_values</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

        <span class="n">variance_explained</span> <span class="o">=</span> <span class="n">squared_values</span> <span class="o">/</span> <span class="n">sum_all_squared_values</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">variance</span> <span class="o">=</span> <span class="n">variance_explained</span>

        <span class="k">return</span> <span class="n">variance_explained</span></div></div>


</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Loghman Samani.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>